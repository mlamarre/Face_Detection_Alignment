{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import menpo\n",
    "import tensorflow as tf\n",
    "import menpo.io as mio\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from tensorflow.python.platform import tf_logging as logging\n",
    "from menpo.image import Image\n",
    "from menpo.shape import PointCloud\n",
    "\n",
    "import numpy as np\n",
    "import menpo.io as mio\n",
    "import scipy.io as sio\n",
    "from io import BytesIO\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "import glob\n",
    "import cv2\n",
    "import scipy\n",
    "import os\n",
    "import os.path\n",
    "from menpo.image import Image\n",
    "from menpo.visualize import print_dynamic, print_progress\n",
    "from scipy.spatial.distance import pdist\n",
    "from pathlib import Path\n",
    "\n",
    "from menpo.shape import PointCloud, PointUndirectedGraph\n",
    "from menpo.transform import Translation, Scale\n",
    "from menpofit.transform import DifferentiableAlignmentSimilarity\n",
    "\n",
    "from menpowidgets import visualize_images\n",
    "from PIL import Image as PImage\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import tensorflow as tf\n",
    "import cmhm3dfa.detect_face as detect_face\n",
    "import cmhm3dfa.networks as networks\n",
    "import cmhm3dfa.data_provider as data_provider\n",
    "import cmhm3dfa.utils as utils\n",
    "from cmhm3dfa.flags import FLAGS\n",
    "\n",
    "np.set_printoptions(3)\n",
    "slim = tf.contrib.slim\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_image_bounding_box(img, bbox, res, base=256., order=1):\n",
    "\n",
    "    center = bbox.centre()\n",
    "    bmin, bmax = bbox.bounds()\n",
    "    scale = np.linalg.norm(bmax - bmin) / base\n",
    "\n",
    "    return crop_image(img, center, scale, res, base, order=order)\n",
    "\n",
    "def crop_image(img, center, scale, res, base=256., order=1):\n",
    "    h = scale\n",
    "\n",
    "    t = Translation(\n",
    "        [\n",
    "            res[0] * (-center[0] / h + .5),\n",
    "            res[1] * (-center[1] / h + .5)\n",
    "        ]).compose_after(Scale((res[0] / h, res[1] / h))).pseudoinverse()\n",
    "\n",
    "    # Upper left point\n",
    "    ul = np.floor(t.apply([0, 0]))\n",
    "    # Bottom right point\n",
    "    br = np.ceil(t.apply(res).astype(np.int))\n",
    "\n",
    "    # crop and rescale\n",
    "    cimg, trans = img.warp_to_shape(\n",
    "        br - ul, Translation(-(br - ul) / 2 + (br + ul) / 2), return_transform=True)\n",
    "\n",
    "    c_scale = np.min(cimg.shape) / np.mean(res)\n",
    "    new_img = cimg.rescale(1 / c_scale, order=order).resize(res, order=order)\n",
    "\n",
    "    trans = trans.compose_after(Scale([c_scale, c_scale]))\n",
    "\n",
    "    return new_img, trans\n",
    "\n",
    "def tf_heatmap_to_lms(heatmap):\n",
    "    hs = tf.argmax(tf.reduce_max(heatmap, 2), 1)\n",
    "    ws = tf.argmax(tf.reduce_max(heatmap, 1), 1)\n",
    "    lms = tf.transpose(tf.to_float(tf.stack([hs, ws])), perm=[1, 2, 0])\n",
    "    return lms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minsize = 40 # minimum size of face\n",
    "threshold = [ 0.6, 0.7, 0.7 ]  # three steps's threshold\n",
    "factor = 0.709 # scale factor\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "with tf.Graph().as_default():\n",
    "    sess = tf.Session(config=config)\n",
    "    with sess.as_default():\n",
    "        pnet, rnet, onet = detect_face.create_detector(sess, '../detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip pre-trained model in home folder - https://drive.google.com/open?id=1DKTeRlJjyo_tD1EluDjYLhtKFPJ9vIVd\n",
    "assert(os.path.exists(os.path.expanduser('~/ckpt/2D68'))) \n",
    "model_path = os.path.expanduser('~/ckpt/2D68/model.ckpt-304332')\n",
    "template = mio.import_pickle('../image/template.pkl.gz')\n",
    "n_landmarks = 68\n",
    "FLAGS.n_landmarks = 68\n",
    "with tf.Graph().as_default() as g:\n",
    "    images_input = tf.placeholder(tf.float32, shape=(None, None, None, 3), name='input_images')\n",
    "    net_model = networks.DNFaceMultiView('')\n",
    "    with tf.variable_scope('net'):\n",
    "        lms_heatmap_prediction,states = net_model._build_network(images_input, datas=None, is_training=False, n_channels=n_landmarks)\n",
    "        pts_predictions = tf_heatmap_to_lms(lms_heatmap_prediction)\n",
    "        variables_to_restore = slim.get_variables_to_restore()\n",
    "        saver = tf.train.Saver(variables_to_restore)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config,graph=g)\n",
    "\n",
    "saver.restore(sess, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# left profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../image/ID01_004.jpg'\n",
    "image = mio.import_image(image_path)  \n",
    "image_path = image.path\n",
    "image_ID_name = image_path.stem\n",
    "bounding_boxes, points = detect_face.detect_face(image.pixels_with_channels_at_back() * 255, minsize, pnet, rnet, onet, threshold, factor)\n",
    "print('Box Number: %s' % bounding_boxes.shape[0])\n",
    "batch_pixels = []\n",
    "batch_trans = []\n",
    "batch_image_names = []\n",
    "\n",
    "for box_index in np.arange(bounding_boxes.shape[0]):\n",
    "    bbox = PointCloud(bounding_boxes[box_index,[1,0,3,2]].reshape([2,2])).bounding_box()\n",
    "    crop_img, crop_trans = crop_image_bounding_box(image, bbox, [256., 256.], base=256./256., order=1)\n",
    "    input_pixels = crop_img.pixels_with_channels_at_back()\n",
    "    batch_pixels.append(input_pixels)\n",
    "    batch_trans.append(crop_trans)\n",
    "    batch_image_names.append('../image/' + image_ID_name + '__' + str(box_index) + '.pts')\n",
    "    \n",
    "pts_pred = sess.run(\n",
    "    pts_predictions,\n",
    "    feed_dict={images_input: np.stack(batch_pixels, axis=0)})\n",
    "\n",
    "for inner_batch_index in np.arange(bounding_boxes.shape[0]):\n",
    "    orig_pts = batch_trans[inner_batch_index].apply(PointCloud(pts_pred[inner_batch_index]))\n",
    "    template.landmarks['SAVEPTS'] = orig_pts\n",
    "    mio.export_landmark_file(template.landmarks['SAVEPTS'], batch_image_names[inner_batch_index],extension='pts', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_index = np.array([17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 27, 26, 24, 23,\n",
    "                           28, 29, 30, 31, 34, 36, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 58, 63, 64, 65, 66, 67])-1\n",
    "\n",
    "image.view()\n",
    "image.landmarks['PTS']= mio.import_landmark_file('../image/ID01_004__0.pts')\n",
    "\n",
    "orig_pts = PointCloud((image.landmarks['PTS'].points[mask_index,0:2]))\n",
    "\n",
    "orig_pts.view(marker_face_colour='b', render_numbering=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# right profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../image/ID01_017.jpg'\n",
    "image = mio.import_image(image_path)  \n",
    "image_path = image.path\n",
    "image_ID_name = image_path.stem\n",
    "bounding_boxes, points = detect_face.detect_face(image.pixels_with_channels_at_back() * 255, minsize, pnet, rnet, onet, threshold, factor)\n",
    "print('Box Number: %s' % bounding_boxes.shape[0])\n",
    "batch_pixels = []\n",
    "batch_trans = []\n",
    "batch_image_names = []\n",
    "\n",
    "for box_index in np.arange(bounding_boxes.shape[0]):\n",
    "    bbox = PointCloud(bounding_boxes[box_index,[1,0,3,2]].reshape([2,2])).bounding_box()\n",
    "    crop_img, crop_trans = crop_image_bounding_box(image, bbox, [256., 256.], base=256./256., order=1)\n",
    "    input_pixels = crop_img.pixels_with_channels_at_back()\n",
    "    batch_pixels.append(input_pixels)\n",
    "    batch_trans.append(crop_trans)\n",
    "    batch_image_names.append('../image/' + image_ID_name + '__' + str(box_index) + '.pts')\n",
    "    \n",
    "pts_pred = sess.run(\n",
    "    pts_predictions,\n",
    "    feed_dict={images_input: np.stack(batch_pixels, axis=0)})\n",
    "\n",
    "for inner_batch_index in np.arange(bounding_boxes.shape[0]):\n",
    "    orig_pts = batch_trans[inner_batch_index].apply(PointCloud(pts_pred[inner_batch_index]))\n",
    "    template.landmarks['SAVEPTS'] = orig_pts\n",
    "    mio.export_landmark_file(template.landmarks['SAVEPTS'], batch_image_names[inner_batch_index],extension='pts', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_index = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18, 19, 21, 22, \n",
    "                           28, 29, 30, 31, 34, 32, 39, 38, 37, 42, 41, 52, 51, 50, 49, 60, 59, 58, 63, 62, 61, 68, 67])-1\n",
    "\n",
    "image.view()\n",
    "image.landmarks['PTS']= mio.import_landmark_file(batch_image_names[0])\n",
    "\n",
    "orig_pts = PointCloud((image.landmarks['PTS'].lms.points[mask_index,0:2]))\n",
    "\n",
    "orig_pts.view(marker_face_colour='b', render_numbering=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# frontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../image/ID01_001.jpg'\n",
    "image = mio.import_image(image_path)  \n",
    "image_path = image.path\n",
    "image_ID_name = image_path.stem\n",
    "bounding_boxes, points = detect_face.detect_face(image.pixels_with_channels_at_back() * 255, minsize, pnet, rnet, onet, threshold, factor)\n",
    "print('Box Number: %s' % bounding_boxes.shape[0])\n",
    "batch_pixels = []\n",
    "batch_trans = []\n",
    "batch_image_names = []\n",
    "\n",
    "for box_index in np.arange(bounding_boxes.shape[0]):\n",
    "    bbox = PointCloud(bounding_boxes[box_index,[1,0,3,2]].reshape([2,2])).bounding_box()\n",
    "    crop_img, crop_trans = crop_image_bounding_box(image, bbox, [256., 256.], base=256./256., order=1)\n",
    "    input_pixels = crop_img.pixels_with_channels_at_back()\n",
    "    batch_pixels.append(input_pixels)\n",
    "    batch_trans.append(crop_trans)\n",
    "    batch_image_names.append('../image/' + image_ID_name + '__' + str(box_index) + '.pts')\n",
    "    \n",
    "pts_pred = sess.run(\n",
    "    pts_predictions,\n",
    "    feed_dict={images_input: np.stack(batch_pixels, axis=0)})\n",
    "\n",
    "for inner_batch_index in np.arange(bounding_boxes.shape[0]):\n",
    "    orig_pts = batch_trans[inner_batch_index].apply(PointCloud(pts_pred[inner_batch_index]))\n",
    "    template.landmarks['SAVEPTS'] = orig_pts\n",
    "    mio.export_landmark_file(template.landmarks['SAVEPTS'], batch_image_names[inner_batch_index],extension='pts', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_index = np.arange(68)\n",
    "image.view()\n",
    "image.landmarks['PTS']= mio.import_landmark_file(batch_image_names[0])\n",
    "\n",
    "template.landmarks['PTS'].lms.points = image.landmarks['PTS'].lms.points\n",
    "lm = template.landmarks['PTS']\n",
    "lm.view(marker_size=5,render_numbering=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
